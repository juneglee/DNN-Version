{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "dacon_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OyjQazUVS4P",
        "outputId": "36bb0dfd-f5db-4b46-95cd-191668df2713"
      },
      "source": [
        "# install konlpy, JPype1, mecab\n",
        "!apt-get update \n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip install konlpy JPype1-py3 \n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "id": "1OyjQazUVS4P",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "openjdk-8-jdk is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 79 not upgraded.\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1-py3 in /usr/local/lib/python3.7/dist-packages (0.5.5.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a3e511f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import copy\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "id": "8a3e511f",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l0P_n1KVcHX",
        "outputId": "fdb25c53-8f0c-41e8-cfe0-c8dd172d7834"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "4l0P_n1KVcHX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bokwKoGnO34g"
      },
      "source": [
        "### 랜던 시드 고정\n"
      ],
      "id": "bokwKoGnO34g"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f914089c"
      },
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore"
      ],
      "id": "f914089c",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "519ad4f4"
      },
      "source": [
        "seed_everything(42)"
      ],
      "id": "519ad4f4",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDoZjbfjO93H"
      },
      "source": [
        "데이터 로드"
      ],
      "id": "uDoZjbfjO93H"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e75078dc"
      },
      "source": [
        "DIR = \"./data\"\n",
        "TRAIN_SOURCE = os.path.join(DIR, \"/content/gdrive/MyDrive/Colab Notebooks/data/dacon/trans/train.json\")\n",
        "TEST_SOURCE = os.path.join(DIR, \"/content/gdrive/MyDrive/Colab Notebooks/data/dacon/trans/test.json\")"
      ],
      "id": "e75078dc",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f1b776e"
      },
      "source": [
        "with open(TRAIN_SOURCE) as f:\n",
        "    TRAIN_DATA = json.loads(f.read())\n",
        "    \n",
        "with open(TEST_SOURCE) as f:\n",
        "    TEST_DATA = json.loads(f.read())"
      ],
      "id": "2f1b776e",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e88a2b29"
      },
      "source": [
        "train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n",
        "uid = 1000\n",
        "for data in TRAIN_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        train.loc[uid, 'uid'] = uid\n",
        "        train.loc[uid, 'title'] = data['title']\n",
        "        train.loc[uid, 'region'] = data['region']\n",
        "        train.loc[uid, 'context'] = context[:-1]\n",
        "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
        "        uid += 1\n",
        "\n",
        "test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n",
        "uid = 2000\n",
        "for data in TEST_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        test.loc[uid, 'uid'] = uid\n",
        "        test.loc[uid, 'title'] = data['title']\n",
        "        test.loc[uid, 'region'] = data['region']\n",
        "        test.loc[uid, 'context'] = context[:-1]\n",
        "        uid += 1"
      ],
      "id": "e88a2b29",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c177e4c0"
      },
      "source": [
        "train['total'] = train.title + ' ' + train.region + ' ' + train.context\n",
        "test['total'] = test.title + ' ' + test.region + ' ' + test.context"
      ],
      "id": "c177e4c0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "824f4ebd",
        "outputId": "10c94b9d-5fa9-4d8f-d2a2-d0ce576f381c"
      },
      "source": [
        "train.head()"
      ],
      "id": "824f4ebd",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>context</th>\n",
              "      <th>summary</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>1000</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>완주</td>\n",
              "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...</td>\n",
              "      <td>제207회 완주군의회 임시회 제1차 본회의 개의 선포.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>1001</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>완주</td>\n",
              "      <td>의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...</td>\n",
              "      <td>제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>1002</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>완주</td>\n",
              "      <td>다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...</td>\n",
              "      <td>제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>1003</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>완주</td>\n",
              "      <td>다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...</td>\n",
              "      <td>8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>1004</td>\n",
              "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록</td>\n",
              "      <td>완주</td>\n",
              "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...</td>\n",
              "      <td>제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.</td>\n",
              "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid  ...                                              total\n",
              "1000  1000  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...\n",
              "1001  1001  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....\n",
              "1002  1002  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...\n",
              "1003  1003  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...\n",
              "1004  1004  ...  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebf80d55",
        "outputId": "b2ace1f6-2c0d-45c6-96f4-035a90430f6b"
      },
      "source": [
        "train.shape"
      ],
      "id": "ebf80d55",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2994, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "1686e606",
        "outputId": "060a7861-de75-4532-a8dc-bead1e13424a"
      },
      "source": [
        "test.head()"
      ],
      "id": "1686e606",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>context</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>2000</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 지금부터 음성군의회 제235회 ...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의석을 정돈하여 주시기 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>2001</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의사일정 제1항, 음성군의회 제235회 제1차 정례회 회기결정의 건을 상정합니다. ...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제1항, 음성군...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>2002</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의사일정 제2항, 회의록 서명의원 선출의 건을 상정합니다. 제235회 제1차 정례회...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제2항, 회의록...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>2003</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의사일정 제3항, 예산결산특별위원회 구성의 건을 상정합니다. 예산결산특별위원회 구성...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제3항, 예산결...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>2004</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의사일정 제4항, 환경분야 현지확인 특별위원회 구성결의안을 상정합니다. 대표발의하신...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제4항, 환경분...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid  ...                                              total\n",
              "2000  2000  ...  제235회    본회의 제1차(2012.06.21.) 음성 의석을 정돈하여 주시기 ...\n",
              "2001  2001  ...  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제1항, 음성군...\n",
              "2002  2002  ...  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제2항, 회의록...\n",
              "2003  2003  ...  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제3항, 예산결...\n",
              "2004  2004  ...  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제4항, 환경분...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15246a9a",
        "outputId": "3b3e5382-f2d1-4d94-a232-4f1c93d18240"
      },
      "source": [
        "test.shape"
      ],
      "id": "15246a9a",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-oVTtjDPDCO"
      },
      "source": [
        "하이퍼 파라미터"
      ],
      "id": "g-oVTtjDPDCO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "425d0b61"
      },
      "source": [
        "encoder_len = 500\n",
        "decoder_len = 50\n",
        "max_vocab_size = 20000\n",
        "batch_size = 32\n",
        "num_layers = 6\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "epochs = 20\n",
        "learning_rate = 1e-4\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "id": "425d0b61",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzQjL3kOPF9z"
      },
      "source": [
        "train, validation 분리"
      ],
      "id": "tzQjL3kOPF9z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7366fb0"
      },
      "source": [
        "df_train = train.iloc[:-200]\n",
        "df_val = train.iloc[-200:]"
      ],
      "id": "d7366fb0",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5QDRf2YPLyg"
      },
      "source": [
        "### **토크나이징**"
      ],
      "id": "m5QDRf2YPLyg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c99173e"
      },
      "source": [
        "class Mecab_Tokenizer():\n",
        "    def __init__(self, max_length, mode, max_vocab_size=-1):\n",
        "        self.text_tokenizer = Mecab()\n",
        "        self.mode = mode\n",
        "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
        "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
        "        self.max_length = max_length\n",
        "        self.word_count = {}\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        \n",
        "        # 띄어쓰기를 찾기 위한 태그 목록\n",
        "        self.font_blank_tag = [\n",
        "            '', 'EC', 'EC+JKO', 'EF', 'EP+EC', 'EP+EP+EC', 'EP+ETM', 'EP+ETN+JKO', 'ETM', 'ETN', 'ETN+JKO', 'ETN+JX', 'IC', 'JC', 'JKB', 'JKB+JX', 'JKO',\n",
        "            'JKQ', 'JKS', 'JX', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ','MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+JKO', 'NNB+VCP+EC', 'NNBC', 'NNG', 'NNG+JX+JKO',\n",
        "            'NNG+VCP+EC', 'NNP', 'NNP+JX', 'NP', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NR', 'SC', 'SF', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'UNKNOWN',\n",
        "            'VA+EC', 'VA+EC+VX+ETM', 'VA+ETM', 'VA+ETN+JKB+JX', 'VCN+EC', 'VCN+ETM', 'VCP', 'VCP+EC', 'VCP+EP+EC', 'VCP+EP+ETM', 'VCP+ETM', 'VCP+ETN',\n",
        "            'VV+EC', 'VV+EC+JX', 'VV+EC+VX+EC', 'VV+EC+VX+ETM', 'VV+EP+EC', 'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VX+EC', 'VX+EC+VX+EP+EC', 'VX+EP+ETM',\n",
        "            'VX+ETM', 'XPN', 'XR', 'XSA+EC', 'XSA+EC+VX+ETM', 'XSA+ETM', 'XSN', 'XSV+EC', 'XSV+EP+EC', 'XSV+ETM', 'XSV+ETN', 'XSV+JKO'\n",
        "        ]\n",
        "        self.back_blank_tag = [\n",
        "            '', 'IC', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ', 'MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+VCP', 'NNB+VCP+EC', 'NNB+VCP+EF', 'NNBC', 'NNBC+VCP+EC',\n",
        "            'NNG', 'NNG+JC', 'NNG+JX+JKO', 'NNG+VCP', 'NNG+VCP+EC', 'NNG+VCP+ETM', 'NNP', 'NNP+JX', 'NP', 'NP+JKG', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NP+VCP+EF',\n",
        "            'NR', 'SC', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'VA', 'VA+EC', 'VA+EC+VX+ETM', 'VA+EF', 'VA+ETM', 'VA+ETN', 'VA+ETN+JKB+JX', 'VCN', 'VCN+EC', 'VCN+EF', 'VCN+ETM',\n",
        "            'VCN+ETN', 'VCP', 'VCP+EF', 'VV', 'VV+EC', 'VV+EC+JX', 'VV+EC+VX', 'VV+EC+VX+EC', 'VV+EC+VX+EF', 'VV+EC+VX+EP+EC', 'VV+EC+VX+ETM', 'VV+EF', 'VV+EP', 'VV+EP+EC',\n",
        "            'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VV+ETN+VCP+EF', 'VX', 'VX+ETM', 'XPN', 'XR', 'XSA+ETN+VCP+EF', 'XSN'\n",
        "        ]\n",
        "        \n",
        "    def morpheme(self, sentence_list):\n",
        "        new_sentence = []\n",
        "        for i, sentence in tqdm(enumerate(sentence_list)):\n",
        "            temp = []\n",
        "            if self.mode == 'dec':\n",
        "                temp.append('sos_')\n",
        "            for t in self.text_tokenizer.pos(sentence):\n",
        "                temp.append('_'.join(t))\n",
        "            if self.mode == 'dec':\n",
        "                temp.append('eos_')\n",
        "            new_sentence.append(' '.join(temp))\n",
        "            \n",
        "        return new_sentence\n",
        "    \n",
        "    def fit(self, sentence_list):\n",
        "        for sentence in tqdm(sentence_list):\n",
        "            for word in sentence.split(' '):\n",
        "                try:\n",
        "                    self.word_count[word] += 1\n",
        "                except:\n",
        "                    self.word_count[word] = 1\n",
        "        self.word_count = dict(sorted(self.word_count.items(), key=self.sort_target, reverse=True))\n",
        "        \n",
        "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
        "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
        "        if self.max_vocab_size == -1:\n",
        "            for i, word in enumerate(list(self.word_count.keys())):\n",
        "                self.txt2idx[word]=i+2\n",
        "                self.idx2txt[i+2]=word\n",
        "        else:\n",
        "            for i, word in enumerate(list(self.word_count.keys())[:self.max_vocab_size]):\n",
        "                self.txt2idx[word]=i+2\n",
        "                self.idx2txt[i+2]=word\n",
        "        \n",
        "    def sort_target(self, x):\n",
        "        return x[1]\n",
        "            \n",
        "    def txt2token(self, sentence_list):\n",
        "        tokens = []\n",
        "        for sentence in tqdm(sentence_list):\n",
        "            token = [0]*self.max_length\n",
        "            for i, w in enumerate(sentence.split(' ')):\n",
        "                if i == self.max_length:\n",
        "                    break\n",
        "                try:\n",
        "                    token[i] = self.txt2idx[w]\n",
        "                except:\n",
        "                    token[i] = self.txt2idx['unk_']\n",
        "            tokens.append(token)\n",
        "        return np.array(tokens)\n",
        "    \n",
        "    def convert(self, token):\n",
        "        sentence = []\n",
        "        for j, i in enumerate(token):\n",
        "            if self.mode == 'enc':\n",
        "                if i != self.txt2idx['pad_']:\n",
        "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
        "            elif self.mode == 'dec':\n",
        "                if i == self.txt2idx['eos_'] or i == self.txt2idx['pad_']:\n",
        "                    break\n",
        "                elif i != 0:\n",
        "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
        "                    # 앞뒤 태그를 확인하여 띄어쓰기 추가\n",
        "                    if self.idx2txt[i].split('_')[1] in self.font_blank_tag:\n",
        "                        try:\n",
        "                            if self.idx2txt[token[j+1]].split('_')[1] in self.back_blank_tag:\n",
        "                                sentence.append(' ')\n",
        "                        except:\n",
        "                            pass\n",
        "        sentence = \"\".join(sentence)\n",
        "        if self.mode == 'enc':\n",
        "            sentence = sentence[:-1]\n",
        "        elif self.mode == 'dec':\n",
        "            sentence = sentence[3:-1]\n",
        "            \n",
        "        return sentence"
      ],
      "id": "8c99173e",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91fcde99"
      },
      "source": [
        "src_tokenizer = Mecab_Tokenizer(encoder_len, mode='enc', max_vocab_size=max_vocab_size)\n",
        "tar_tokenizer = Mecab_Tokenizer(decoder_len, mode='dec', max_vocab_size=max_vocab_size)"
      ],
      "id": "91fcde99",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b66d304b",
        "outputId": "ff1b9fca-c891-44b9-b8da-ebf8f1f54cef"
      },
      "source": [
        "train_src = src_tokenizer.morpheme(df_train.total)\n",
        "val_src = src_tokenizer.morpheme(df_val.total)\n",
        "test_src = src_tokenizer.morpheme(test.total)\n",
        "\n",
        "train_tar = tar_tokenizer.morpheme(df_train.summary)\n",
        "val_tar = tar_tokenizer.morpheme(df_val.summary)"
      ],
      "id": "b66d304b",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2794it [00:13, 205.39it/s]\n",
            "200it [00:00, 264.02it/s]\n",
            "506it [00:02, 236.25it/s]\n",
            "2794it [00:00, 4467.19it/s]\n",
            "200it [00:00, 4587.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "63ae09cc",
        "outputId": "3f596fdd-b590-49bb-aad1-b2e129c6e442"
      },
      "source": [
        "train_src_len = []\n",
        "for m in train_src:\n",
        "    m_len = len(m.split(' '))\n",
        "    train_src_len.append(m_len)\n",
        "print('train_src_max_len :', max(train_src_len))\n",
        "plt.hist(train_src_len, bins=30)\n",
        "plt.show()\n",
        "\n",
        "train_tar_len = []\n",
        "for m in train_tar:\n",
        "    m_len = len(m.split(' '))\n",
        "    train_tar_len.append(m_len)\n",
        "print('train_tar_max_len :', max(train_tar_len))\n",
        "plt.hist(train_tar_len, bins=30)\n",
        "plt.show()"
      ],
      "id": "63ae09cc",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_src_max_len : 6476\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARnUlEQVR4nO3df6zd9V3H8efLdjC3GVrghmDb2C42GjTq8IZBWJZlVcavrPyxTYhxdWIalekUk624RKLGhKnZDxJFG0BLgjDETZoNxQoY4x+wXTbG+DHGHSu2Dax344c/ljnRt3+cT7dD1/b23nN7bk8/z0dycj7fz/dzvt/3KV9e59vP93tOU1VIkvrwfctdgCRpfAx9SeqIoS9JHTH0Jakjhr4kdWTlchdwJKeffnqtX79+ucuQpIny0EMPfb2qpg617rgO/fXr1zMzM7PcZUjSREnyzOHWOb0jSR0x9CWpI4a+JHXE0Jekjhj6ktSReUM/yc1J9id5dKjvj5N8KckjST6ZZNXQumuSzCZ5MsnbhvovbH2zSbYt/VuRJM3naM70/wq48KC+XcCPV9VPAF8GrgFIchZwOfBj7TV/lmRFkhXAnwIXAWcBV7SxkqQxmjf0q+pfgOcP6vvHqnq5LT4ArG3tzcDtVfXfVfVVYBY4pz1mq+rpqvo2cHsbK0kao6WY0/8l4O9bew2wZ2jd3tZ3uP7vkWRrkpkkM3Nzc0tQniTpgJG+kZvkg8DLwK1LUw5U1XZgO8D09PRI/8LL+m2fPqpxu6+7ZJTdSNLEWHToJ/lF4FJgU333n9/aB6wbGra29XGEfknSmCxqeifJhcD7gbdX1TeHVu0ELk9ycpINwEbgM8BngY1JNiQ5icHF3p2jlS5JWqh5z/ST3Aa8BTg9yV7gWgZ365wM7EoC8EBV/UpVPZbkDuBxBtM+V1XV/7btvBe4B1gB3FxVjx2D9yNJOoJ5Q7+qrjhE901HGP+HwB8eov9u4O4FVSdJWlJ+I1eSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JH5g39JDcn2Z/k0aG+U5PsSvJUe17d+pPk+iSzSR5JcvbQa7a08U8l2XJs3o4k6UiO5kz/r4ALD+rbBtxbVRuBe9sywEXAxvbYCtwAgw8J4FrgjcA5wLUHPigkSeMzb+hX1b8Azx/UvRnY0do7gMuG+m+pgQeAVUnOBN4G7Kqq56vqBWAX3/tBIkk6xhY7p39GVT3b2s8BZ7T2GmDP0Li9re9w/d8jydYkM0lm5ubmFlmeJOlQRr6QW1UF1BLUcmB726tquqqmp6amlmqzkiQWH/pfa9M2tOf9rX8fsG5o3NrWd7h+SdIYLTb0dwIH7sDZAtw11P/udhfPucBLbRroHuCCJKvbBdwLWp8kaYxWzjcgyW3AW4DTk+xlcBfOdcAdSa4EngHe1YbfDVwMzALfBN4DUFXPJ/kD4LNt3O9X1cEXhyVJx9i8oV9VVxxm1aZDjC3gqsNs52bg5gVVJ0laUn4jV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MlLoJ/mtJI8leTTJbUlenWRDkgeTzCb5eJKT2tiT2/JsW79+Kd6AJOnoLTr0k6wBfgOYrqofB1YAlwMfAj5SVT8MvABc2V5yJfBC6/9IGydJGqNRp3dWAt+fZCXwGuBZ4K3AnW39DuCy1t7clmnrNyXJiPuXJC3AokO/qvYBfwL8G4Owfwl4CHixql5uw/YCa1p7DbCnvfblNv60g7ebZGuSmSQzc3Nziy1PknQIo0zvrGZw9r4B+EHgtcCFoxZUVdurarqqpqempkbdnCRpyCjTOz8DfLWq5qrqf4BPAOcDq9p0D8BaYF9r7wPWAbT1pwDfGGH/kqQFGiX0/w04N8lr2tz8JuBx4H7gHW3MFuCu1t7Zlmnr76uqGmH/kqQFGmVO/0EGF2Q/B3yxbWs78AHg6iSzDObsb2ovuQk4rfVfDWwboW5J0iKsnH/I4VXVtcC1B3U/DZxziLHfAt45yv4kSaPxG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MlLoJ1mV5M4kX0ryRJLzkpyaZFeSp9rz6jY2Sa5PMpvkkSRnL81bkCQdrVHP9D8G/ENV/Sjwk8ATwDbg3qraCNzblgEuAja2x1bghhH3LUlaoEWHfpJTgDcDNwFU1ber6kVgM7CjDdsBXNbam4FbauABYFWSMxdduSRpwUY5098AzAF/meTzSW5M8lrgjKp6to15DjijtdcAe4Zev7f1vUKSrUlmkszMzc2NUJ4k6WCjhP5K4Gzghqp6A/BffHcqB4CqKqAWstGq2l5V01U1PTU1NUJ5kqSDjRL6e4G9VfVgW76TwYfA1w5M27Tn/W39PmDd0OvXtj5J0pgsOvSr6jlgT5IfaV2bgMeBncCW1rcFuKu1dwLvbnfxnAu8NDQNJEkag5Ujvv7XgVuTnAQ8DbyHwQfJHUmuBJ4B3tXG3g1cDMwC32xjJUljNFLoV9XDwPQhVm06xNgCrhplf5Kk0fiNXEnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyMpRN5BkBTAD7KuqS5NsAG4HTgMeAn6hqr6d5GTgFuCngW8AP1dVu0fd/1JYv+3TRzVu93WXHONKJOnYWooz/fcBTwwtfwj4SFX9MPACcGXrvxJ4ofV/pI2TJI3RSKGfZC1wCXBjWw7wVuDONmQHcFlrb27LtPWb2nhJ0piMeqb/UeD9wP+15dOAF6vq5ba8F1jT2muAPQBt/UttvCRpTBYd+kkuBfZX1UNLWA9JtiaZSTIzNze3lJuWpO6NcqZ/PvD2JLsZXLh9K/AxYFWSAxeI1wL7WnsfsA6grT+FwQXdV6iq7VU1XVXTU1NTI5QnSTrYokO/qq6pqrVVtR64HLivqn4euB94Rxu2BbirtXe2Zdr6+6qqFrt/SdLCHYv79D8AXJ1klsGc/U2t/ybgtNZ/NbDtGOxbknQEI9+nD1BV/wz8c2s/DZxziDHfAt65FPuTJC2O38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdWbncBZyI1m/79FGN233dJce4Ekl6JUN/AY42zCXpeOX0jiR1xNCXpI4sOvSTrEtyf5LHkzyW5H2t/9Qku5I81Z5Xt/4kuT7JbJJHkpy9VG9CknR0RjnTfxn47ao6CzgXuCrJWcA24N6q2gjc25YBLgI2tsdW4IYR9i1JWoRFh35VPVtVn2vt/wCeANYAm4EdbdgO4LLW3gzcUgMPAKuSnLnoyiVJC7Ykc/pJ1gNvAB4EzqiqZ9uq54AzWnsNsGfoZXtb38Hb2ppkJsnM3NzcUpQnSWpGDv0krwP+FvjNqvr34XVVVUAtZHtVtb2qpqtqempqatTyJElDRgr9JK9iEPi3VtUnWvfXDkzbtOf9rX8fsG7o5WtbnyRpTEa5eyfATcATVfXhoVU7gS2tvQW4a6j/3e0unnOBl4amgSRJYzDKN3LPB34B+GKSh1vf7wDXAXckuRJ4BnhXW3c3cDEwC3wTeM8I+5YkLcKiQ7+q/hXIYVZvOsT4Aq5a7P4kSaPzt3eWkT/MJmnc/BkGSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFv2ZwAC/lnGr29U9KReKYvSR0x9CWpI4a+JHXE0Jekjngh9wTj7/lIOhLP9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kd8ctZnVrIL3ceDb/sJU0GQ19Lwm8CS5PB6R1J6ohn+ppo/gMz0sIY+hqrpb6WIGlhxh76SS4EPgasAG6squvGXYP65HUHacyhn2QF8KfAzwJ7gc8m2VlVj4+zDulIjve/jRyLDyU/EPsx7jP9c4DZqnoaIMntwGbA0JeO0vH+oQSTUeNSO9oPxOX+gB136K8B9gwt7wXeODwgyVZga1v8zyRPLmI/pwNfX1SFy8/al88k1z+W2vOhY7LZSf5zh1b/Uv/ZjLi9HzrciuPuQm5VbQe2j7KNJDNVNb1EJY2VtS+fSa7f2pfPpNU/7vv09wHrhpbXtj5J0hiMO/Q/C2xMsiHJScDlwM4x1yBJ3Rrr9E5VvZzkvcA9DG7ZvLmqHjsGuxppemiZWfvymeT6rX35TFT9qarlrkGSNCb+9o4kdcTQl6SOnFChn+TCJE8mmU2ybbnrOSDJzUn2J3l0qO/UJLuSPNWeV7f+JLm+vYdHkpw99JotbfxTSbaMqfZ1Se5P8niSx5K8b1LqT/LqJJ9J8oVW+++1/g1JHmw1frzdVECSk9vybFu/fmhb17T+J5O87VjXPrTfFUk+n+RTE1j77iRfTPJwkpnWd9wfN22fq5LcmeRLSZ5Ict6k1D6vqjohHgwuDH8FeD1wEvAF4KzlrqvV9mbgbODRob4/Ara19jbgQ619MfD3QIBzgQdb/6nA0+15dWuvHkPtZwJnt/YPAF8GzpqE+lsNr2vtVwEPtpruAC5v/X8O/Gpr/xrw5619OfDx1j6rHU8nAxvacbZiTMfO1cBfA59qy5NU+27g9IP6jvvjpu13B/DLrX0SsGpSap/3vS13AUv4H+k84J6h5WuAa5a7rqF61vPK0H8SOLO1zwSebO2/AK44eBxwBfAXQ/2vGDfG93EXg99Omqj6gdcAn2PwDfCvAysPPm4Y3FV2XmuvbONy8LE0PO4Y17wWuBd4K/CpVstE1N72tZvvDf3j/rgBTgG+SrvRZZJqP5rHiTS9c6ifeFizTLUcjTOq6tnWfg44o7UP9z6W/f21KYM3MDhjnoj62/TIw8B+YBeDM90Xq+rlQ9TxnRrb+peA05arduCjwPuB/2vLpzE5tQMU8I9JHsrg51VgMo6bDcAc8Jdtau3GJK9lMmqf14kU+hOrBqcBx/W9s0leB/wt8JtV9e/D647n+qvqf6vqpxicNZ8D/Ogyl3RUklwK7K+qh5a7lhG8qarOBi4Crkry5uGVx/Fxs5LBdOwNVfUG4L8YTOd8x3Fc+7xOpNCftJ94+FqSMwHa8/7Wf7j3sWzvL8mrGAT+rVX1idY9MfUDVNWLwP0MpkRWJTnwxcThOr5TY1t/CvANlqf284G3J9kN3M5giudjE1I7AFW1rz3vBz7J4EN3Eo6bvcDeqnqwLd/J4ENgEmqf14kU+pP2Ew87gQNX87cwmCs/0P/udkfAucBL7a+U9wAXJFnd7hq4oPUdU0kC3AQ8UVUfnqT6k0wlWdXa38/gWsQTDML/HYep/cB7egdwXzuj2wlc3u6Q2QBsBD5zLGuvqmuqam1VrWdwLN9XVT8/CbUDJHltkh840Gbw3/tRJuC4qarngD1JfqR1bWLw8+/Hfe1HZbkvKizlg8FV9C8zmLf94HLXM1TXbcCzwP8wOIu4ksF8673AU8A/Aae2sWHwD818BfgiMD20nV8CZtvjPWOq/U0M/hr7CPBwe1w8CfUDPwF8vtX+KPC7rf/1DIJvFvgb4OTW/+q2PNvWv35oWx9s7+lJ4KIxHz9v4bt370xE7a3OL7THYwf+f5yE46bt86eAmXbs/B2Du28movb5Hv4MgyR15ESa3pEkzcPQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR35f09mzkKAgdocAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_tar_max_len : 342\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1dd5ec6",
        "outputId": "4c95c8ef-809d-47b2-eb67-43daa7c826f6"
      },
      "source": [
        "src_tokenizer.fit(train_src)\n",
        "tar_tokenizer.fit(train_tar)"
      ],
      "id": "b1dd5ec6",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2794/2794 [00:00<00:00, 4200.39it/s]\n",
            "100%|██████████| 2794/2794 [00:00<00:00, 73143.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aa82cd9",
        "outputId": "64ac00a5-b0c0-498f-9b4a-811405fa523f"
      },
      "source": [
        "train_src_tokens = src_tokenizer.txt2token(train_src)\n",
        "val_src_tokens = src_tokenizer.txt2token(val_src)\n",
        "test_src_tokens = src_tokenizer.txt2token(test_src)\n",
        "\n",
        "train_tar_tokens = tar_tokenizer.txt2token(train_tar)\n",
        "val_tar_tokens = tar_tokenizer.txt2token(val_tar)"
      ],
      "id": "0aa82cd9",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2794/2794 [00:00<00:00, 6527.24it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 6774.07it/s]\n",
            "100%|██████████| 506/506 [00:00<00:00, 6370.59it/s]\n",
            "100%|██████████| 2794/2794 [00:00<00:00, 43965.71it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 34242.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb7e1538"
      },
      "source": [
        "input_vocab_size = len(src_tokenizer.txt2idx)\n",
        "target_vocab_size = len(tar_tokenizer.txt2idx)"
      ],
      "id": "bb7e1538",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f94d7904",
        "outputId": "90e90ec1-738d-43e2-b599-cb4a379f59a3"
      },
      "source": [
        "input_vocab_size, target_vocab_size"
      ],
      "id": "f94d7904",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20002, 4877)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "466f330e",
        "outputId": "9e067dcb-6a66-4406-d609-ec8401012b7f"
      },
      "source": [
        "df_train.summary.iloc[0]"
      ],
      "id": "466f330e",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'제207회 완주군의회 임시회 제1차 본회의 개의 선포.'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91991325",
        "outputId": "39cc7e72-1b4f-41c8-9ea9-8f3bc860a9bb"
      },
      "source": [
        "train_tar_tokens[0], tar_tokenizer.convert(train_tar_tokens[0])"
      ],
      "id": "91991325",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   3,    8, 1131,   19,   42,   21,   24,    8,   35,   25,   49,\n",
              "           5,   44,    5,   52,    2,    4,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0]),\n",
              " ' 제 207 회 완주군 의회 임시회 제 1 차 본회의개의선포.')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ0Rwfl0PRt7"
      },
      "source": [
        "### Dataset"
      ],
      "id": "fZ0Rwfl0PRt7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7921053"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, src_tokens, tar_tokens, mode='train'):\n",
        "        self.mode = mode\n",
        "        self.src_tokens = src_tokens\n",
        "        if self.mode == 'train':\n",
        "            self.tar_tokens = tar_tokens\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.src_tokens)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        src_token = self.src_tokens[i]\n",
        "        if self.mode == 'train':\n",
        "            tar_token = self.tar_tokens[i]\n",
        "            return {\n",
        "                'src_token' : torch.tensor(src_token, dtype=torch.long),\n",
        "                'tar_token' : torch.tensor(tar_token, dtype=torch.long),\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'src_token' : torch.tensor(src_token, dtype=torch.long)\n",
        "            }"
      ],
      "id": "b7921053",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4107d211"
      },
      "source": [
        "train_dataset = CustomDataset(train_src_tokens, train_tar_tokens)\n",
        "val_dataset = CustomDataset(val_src_tokens, val_tar_tokens)\n",
        "test_dataset = CustomDataset(test_src_tokens, None, 'test')\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=1, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, shuffle=False)"
      ],
      "id": "4107d211",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUgcs6aHPbHo"
      },
      "source": [
        "### **모델 Transformer**\n",
        "- https://www.tensorflow.org/text/tutorials/transformer 를 pytorch코드로 수정하여 작성"
      ],
      "id": "FUgcs6aHPbHo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "145e54fb"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "id": "145e54fb",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61034418"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return torch.tensor(pos_encoding, dtype=torch.float32)"
      ],
      "id": "61034418",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVWJrPNRendU"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding\n",
        "    # to the attention logits.\n",
        "    seq = seq.unsqueeze(1).unsqueeze(2)\n",
        "    return seq  # (batch_size, 1, 1, seq_len)\n"
      ],
      "id": "eVWJrPNRendU",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSFiAob3eomM"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = torch.ones(size, size).triu(diagonal=1)\n",
        "    return mask  # (seq_len, seq_len)"
      ],
      "id": "sSFiAob3eomM",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXQ11H8tep2T"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = torch.matmul(q, torch.transpose(k, -2, -1))  # (..., seq_len_q, seq_len_k)\n",
        "    \n",
        "    # scale matmul_qk\n",
        "    dk = k.size()[-1]\n",
        "    scaled_attention_logits = matmul_qk / math.sqrt(dk)\n",
        "    \n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = torch.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "id": "HXQ11H8tep2T",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCIea3sOeq7S"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "    temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "    print('Attention weights are:')\n",
        "    print(temp_attn)\n",
        "    print('Output is:')\n",
        "    print(temp_out)"
      ],
      "id": "XCIea3sOeq7S",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b22fece",
        "outputId": "d79375f8-7dfa-4c6f-e5fa-a7742803e6de"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = torch.tensor([[10, 0, 0],\n",
        "                      [0, 10, 0],\n",
        "                      [0, 0, 10],\n",
        "                      [0, 0, 10]], dtype=torch.float32)  # (4, 3)\n",
        "\n",
        "temp_v = torch.tensor([[1, 0],\n",
        "                      [10, 0],\n",
        "                      [100, 5],\n",
        "                      [1000, 6]], dtype=torch.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = torch.tensor([[0, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "id": "9b22fece",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26]])\n",
            "Output is:\n",
            "tensor([[1.0000e+01, 9.2766e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5e49c14",
        "outputId": "2f95c673-bbb7-4141-8889-e64611446f73"
      },
      "source": [
        "temp_q = torch.tensor([[10, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "id": "a5e49c14",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
            "Output is:\n",
            "tensor([[5.5000e+00, 4.6383e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41fe40cd",
        "outputId": "65754e86-a798-4dbe-e9a7-f0586e068e8d"
      },
      "source": [
        "temp_q = torch.tensor([[0, 0, 10],\n",
        "                      [0, 10, 0],\n",
        "                      [10, 10, 0]], dtype=torch.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "id": "41fe40cd",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[4.2166e-26, 4.2166e-26, 5.0000e-01, 5.0000e-01],\n",
            "        [8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26],\n",
            "        [5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
            "Output is:\n",
            "tensor([[5.5000e+02, 5.5000e+00],\n",
            "        [1.0000e+01, 9.2766e-25],\n",
            "        [5.5000e+00, 4.6383e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21dfebff"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = nn.Linear(d_model, d_model)\n",
        "        self.wk = nn.Linear(d_model, d_model)\n",
        "        self.wv = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.wo = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, v, k, q, mask):\n",
        "        batch_size = q.size()[0]\n",
        "        \n",
        "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        \n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        \n",
        "        scaled_attention = scaled_attention.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.depth)\n",
        "                \n",
        "        output = self.wo(scaled_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "id": "21dfebff",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c39da00",
        "outputId": "8918b5eb-1d58-45f6-9f3c-5696bf62cc40"
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = torch.rand(1, 60, 512)  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "id": "8c39da00",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 60, 512]), torch.Size([1, 8, 60, 60]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1196d30"
      },
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, d_model, dff):\n",
        "        super(FFN, self).__init__()\n",
        "        self.layer1 = nn.Linear(d_model, dff)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.fc = nn.Linear(dff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "id": "c1196d30",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d516f50"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = FFN(d_model, dff)\n",
        "        \n",
        "        self.layernorm1 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
        "        self.layernorm2 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(rate)\n",
        "        self.dropout2 = nn.Dropout(rate)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2"
      ],
      "id": "2d516f50",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ecf5668",
        "outputId": "d4e823d0-7a2e-4020-e80b-6d2581f2b4fd"
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048, encoder_len)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    torch.rand(64, encoder_len, 512), None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "id": "8ecf5668",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 500, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ec469a0"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        \n",
        "        self.ffn = FFN(d_model, dff)\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(rate)\n",
        "        self.dropout2 = nn.Dropout(rate)\n",
        "        self.dropout3 = nn.Dropout(rate)\n",
        "        \n",
        "        self.layernorms1 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "        self.layernorms2 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "        self.layernorms3 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "\n",
        "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1)\n",
        "        out1 = self.layernorms1[x.size(1)-1](attn1 + x)\n",
        "        \n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2)\n",
        "        out2 = self.layernorms2[x.size(1)-1](attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "        \n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output)\n",
        "        out3 = self.layernorms3[x.size(1)-1](ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "        \n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "id": "5ec469a0",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692e07a6",
        "outputId": "0971065c-e4d1-40e2-b9ab-b8796c91d1df"
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048, decoder_len)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    torch.rand(64, decoder_len, 512), sample_encoder_layer_output,\n",
        "    None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "id": "692e07a6",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 50, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73b2ce9b"
      },
      "source": [
        "def clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ],
      "id": "73b2ce9b",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b8421db"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
        "        \n",
        "        self.dec_layers = clones(EncoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "\n",
        "    def forward(self, x, mask, enc_output=None):\n",
        "        if enc_output == None:\n",
        "            seq_len = x.size()[1]\n",
        "            attention_weights = {}\n",
        "            x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "            x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
        "            x += self.pos_encoding[:, :seq_len, :]\n",
        "            x = self.dropout(x)\n",
        "            for i in range(self.num_layers):\n",
        "                x = self.dec_layers[i](x, mask)\n",
        "        else:\n",
        "            x = enc_output\n",
        "            \n",
        "        return x"
      ],
      "id": "9b8421db",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47a73a53"
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, input_vocab_size=input_vocab_size,\n",
        "                         maximum_position_encoding=encoder_len,\n",
        "                         device='cpu')\n",
        "\n",
        "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))"
      ],
      "id": "47a73a53",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xJ5OqUp9YA8",
        "outputId": "d6a5e214-091d-4759-9764-07a867ecd786"
      },
      "source": [
        "sample_encoder_output = sample_encoder(temp_input, mask=None, enc_output=None)\n",
        "\n",
        "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "id": "3xJ5OqUp9YA8",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 500, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c9774b2"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
        "        \n",
        "        self.dec_layers = clones(DecoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "        \n",
        "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        seq_len = x.size()[1]\n",
        "        attention_weights = {}\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "            \n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "id": "4c9774b2",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4960b05e"
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, target_vocab_size=target_vocab_size,\n",
        "                         maximum_position_encoding=decoder_len,\n",
        "                         device='cpu')\n",
        "\n",
        "temp_input = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))"
      ],
      "id": "4960b05e",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq2q_DXOMrSy",
        "outputId": "937bef2d-c604-46c7-860e-10c74aa34263"
      },
      "source": [
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "id": "iq2q_DXOMrSy",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 50, 512]), torch.Size([64, 8, 50, 500]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad25b50f"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, device, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                                 input_vocab_size, pe_input, device, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                               target_vocab_size, pe_target, device, rate)\n",
        "\n",
        "        self.final_layer = nn.Linear(d_model, target_vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inp, tar, enc_output = inputs\n",
        "\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
        "\n",
        "        enc_output = self.encoder(inp, enc_padding_mask, enc_output)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights, enc_output\n",
        "\n",
        "    def create_masks(self, inp, tar):\n",
        "        # Encoder padding mask\n",
        "        enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "        # Used in the 2nd attention block in the decoder.\n",
        "        # This padding mask is used to mask the encoder outputs.\n",
        "        dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "        # Used in the 1st attention block in the decoder.\n",
        "        # It is used to pad and mask future tokens in the input received by\n",
        "        # the decoder.\n",
        "        look_ahead_mask = create_look_ahead_mask(tar.size(1))\n",
        "        dec_target_padding_mask = create_padding_mask(tar)\n",
        "        look_ahead_mask = torch.maximum(dec_target_padding_mask.to(self.device), look_ahead_mask.to(self.device))\n",
        "\n",
        "        return enc_padding_mask, look_ahead_mask, dec_padding_mask"
      ],
      "id": "ad25b50f",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2fsFBVg7Z4M"
      },
      "source": [
        "# sample_transformer = Transformer(\n",
        "#     num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
        "#     input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size,\n",
        "#     pe_input=encoder_len, pe_target=decoder_len, device='cpu')\n",
        "\n",
        "# temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
        "# temp_target = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
        "\n",
        "# fn_out, _, _ = sample_transformer([temp_input, temp_target, None])\n",
        "# fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "id": "D2fsFBVg7Z4M",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8999ac2"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=input_vocab_size,\n",
        "    target_vocab_size=target_vocab_size,\n",
        "    pe_input=encoder_len,\n",
        "    pe_target=decoder_len-1,\n",
        "    device=device,\n",
        "    rate=dropout_rate\n",
        ")\n",
        "\n",
        "transformer = transformer.to(device)"
      ],
      "id": "d8999ac2",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFi3W0aAPo-v"
      },
      "source": [
        "### optimizer, loss function"
      ],
      "id": "SFi3W0aAPo-v"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eed9406"
      },
      "source": [
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "id": "9eed9406",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8dc9914"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = torch.logical_not(torch.eq(real, 0))\n",
        "    loss_ = criterion(pred.permute(0,2,1), real)\n",
        "    mask = torch.tensor(mask, dtype=loss_.dtype)\n",
        "    loss_ = mask * loss_\n",
        "\n",
        "    return torch.sum(loss_)/torch.sum(mask)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = torch.eq(real, torch.argmax(pred, dim=2))\n",
        "    mask = torch.logical_not(torch.eq(real, 0))\n",
        "    accuracies = torch.logical_and(mask, accuracies)\n",
        "    accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
        "    mask = torch.tensor(mask, dtype=torch.float32)\n",
        "    \n",
        "    return torch.sum(accuracies)/torch.sum(mask)"
      ],
      "id": "a8dc9914",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62501ca5"
      },
      "source": [
        "def train_step(batch_item, epoch, batch, training):\n",
        "    src = batch_item['src_token'].to(device)\n",
        "    tar = batch_item['tar_token'].to(device)\n",
        "    \n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "    \n",
        "    if training is True:\n",
        "        transformer.train()\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output, _, _ = transformer([src, tar_inp, None])\n",
        "            loss = loss_function(tar_real, output)\n",
        "        acc = accuracy_function(tar_real, output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        return loss, acc, round(lr, 10)\n",
        "    else:\n",
        "        transformer.eval()\n",
        "        with torch.no_grad():\n",
        "            output, _, _ = transformer([src, tar_inp, None])\n",
        "            loss = loss_function(tar_real, output)\n",
        "        acc = accuracy_function(tar_real, output)\n",
        "        return loss, acc"
      ],
      "id": "62501ca5",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiDhQ1eyPwc_"
      },
      "source": [
        "### **training**"
      ],
      "id": "FiDhQ1eyPwc_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a9d45ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8f7f12-b557-494b-d573-eccac70700a3"
      },
      "source": [
        "loss_plot, val_loss_plot = [], []\n",
        "acc_plot, val_acc_plot = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gc.collect()\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_acc, total_val_acc = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc, lr = train_step(batch_item, epoch, batch, training)\n",
        "        total_loss += batch_loss\n",
        "        total_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'LR' : lr,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
        "            'Total ACC' : '{:06f}'.format(total_acc/(batch+1))\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    acc_plot.append(total_acc/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, epoch, batch, training)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
        "            'Total Val ACC' : '{:06f}'.format(total_val_acc/(batch+1))\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    val_acc_plot.append(total_val_acc/(batch+1))"
      ],
      "id": "1a9d45ce",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "88it [05:47,  3.95s/it, Epoch=1, LR=0.0001, Loss=3.532964, Total Loss=3.959733, Total ACC=0.157017]\n",
            "7it [00:04,  1.46it/s, Epoch=1, Val Loss=6.658851, Total Val Loss=3.170129, Total Val ACC=0.326600]\n",
            "88it [05:46,  3.94s/it, Epoch=2, LR=0.0001, Loss=1.974560, Total Loss=2.487167, Total ACC=0.407205]\n",
            "7it [00:04,  1.46it/s, Epoch=2, Val Loss=6.265391, Total Val Loss=2.642256, Total Val ACC=0.429345]\n",
            "88it [05:46,  3.93s/it, Epoch=3, LR=0.0001, Loss=2.328441, Total Loss=2.108702, Total ACC=0.472243]\n",
            "7it [00:04,  1.47it/s, Epoch=3, Val Loss=6.036626, Total Val Loss=2.431253, Total Val ACC=0.463075]\n",
            "88it [05:45,  3.93s/it, Epoch=4, LR=0.0001, Loss=1.265586, Total Loss=1.887187, Total ACC=0.507284]\n",
            "7it [00:04,  1.48it/s, Epoch=4, Val Loss=5.860434, Total Val Loss=2.300465, Total Val ACC=0.485988]\n",
            "88it [05:45,  3.92s/it, Epoch=5, LR=0.0001, Loss=1.410060, Total Loss=1.740668, Total ACC=0.534007]\n",
            "7it [00:04,  1.47it/s, Epoch=5, Val Loss=5.756625, Total Val Loss=2.212753, Total Val ACC=0.503567]\n",
            "88it [05:45,  3.93s/it, Epoch=6, LR=0.0001, Loss=2.613665, Total Loss=1.634931, Total ACC=0.553016]\n",
            "7it [00:04,  1.47it/s, Epoch=6, Val Loss=5.749987, Total Val Loss=2.166970, Total Val ACC=0.513497]\n",
            "88it [05:45,  3.92s/it, Epoch=7, LR=0.0001, Loss=0.803367, Total Loss=1.526503, Total ACC=0.570289]\n",
            "7it [00:04,  1.48it/s, Epoch=7, Val Loss=5.657452, Total Val Loss=2.098253, Total Val ACC=0.527968]\n",
            "88it [05:45,  3.93s/it, Epoch=8, LR=0.0001, Loss=0.960995, Total Loss=1.438312, Total ACC=0.587227]\n",
            "7it [00:04,  1.47it/s, Epoch=8, Val Loss=5.662950, Total Val Loss=2.074427, Total Val ACC=0.533780]\n",
            "88it [05:45,  3.93s/it, Epoch=9, LR=0.0001, Loss=1.419833, Total Loss=1.367823, Total ACC=0.603439]\n",
            "7it [00:04,  1.48it/s, Epoch=9, Val Loss=5.564868, Total Val Loss=2.022781, Total Val ACC=0.543820]\n",
            "88it [05:45,  3.93s/it, Epoch=10, LR=0.0001, Loss=1.241604, Total Loss=1.286007, Total ACC=0.618203]\n",
            "7it [00:04,  1.47it/s, Epoch=10, Val Loss=5.605801, Total Val Loss=2.008749, Total Val ACC=0.548125]\n",
            "88it [05:45,  3.92s/it, Epoch=11, LR=0.0001, Loss=0.780584, Total Loss=1.215274, Total ACC=0.633667]\n",
            "7it [00:04,  1.47it/s, Epoch=11, Val Loss=5.559386, Total Val Loss=1.983785, Total Val ACC=0.553295]\n",
            "88it [05:45,  3.92s/it, Epoch=12, LR=0.0001, Loss=0.922614, Total Loss=1.148573, Total ACC=0.647509]\n",
            "7it [00:04,  1.47it/s, Epoch=12, Val Loss=5.624160, Total Val Loss=1.982739, Total Val ACC=0.552817]\n",
            "88it [05:45,  3.92s/it, Epoch=13, LR=0.0001, Loss=0.613867, Total Loss=1.084962, Total ACC=0.663350]\n",
            "7it [00:04,  1.47it/s, Epoch=13, Val Loss=5.592224, Total Val Loss=1.966494, Total Val ACC=0.557313]\n",
            "88it [05:45,  3.92s/it, Epoch=14, LR=0.0001, Loss=0.723320, Total Loss=1.024678, Total ACC=0.675162]\n",
            "7it [00:04,  1.47it/s, Epoch=14, Val Loss=5.637415, Total Val Loss=1.969153, Total Val ACC=0.564783]\n",
            "88it [05:45,  3.92s/it, Epoch=15, LR=0.0001, Loss=1.423109, Total Loss=0.968378, Total ACC=0.690648]\n",
            "7it [00:04,  1.47it/s, Epoch=15, Val Loss=5.706695, Total Val Loss=1.972249, Total Val ACC=0.565718]\n",
            "88it [05:45,  3.92s/it, Epoch=16, LR=0.0001, Loss=0.805310, Total Loss=0.910263, Total ACC=0.705188]\n",
            "7it [00:04,  1.47it/s, Epoch=16, Val Loss=5.672576, Total Val Loss=1.950887, Total Val ACC=0.575514]\n",
            "88it [05:46,  3.94s/it, Epoch=17, LR=0.0001, Loss=0.768934, Total Loss=0.848181, Total ACC=0.721333]\n",
            "7it [00:04,  1.44it/s, Epoch=17, Val Loss=5.698376, Total Val Loss=1.960388, Total Val ACC=0.571450]\n",
            "88it [05:48,  3.96s/it, Epoch=18, LR=0.0001, Loss=0.592765, Total Loss=0.794665, Total ACC=0.736726]\n",
            "7it [00:04,  1.45it/s, Epoch=18, Val Loss=5.684936, Total Val Loss=1.953701, Total Val ACC=0.576507]\n",
            "88it [05:48,  3.96s/it, Epoch=19, LR=0.0001, Loss=0.895712, Total Loss=0.747148, Total ACC=0.752168]\n",
            "7it [00:04,  1.45it/s, Epoch=19, Val Loss=5.716649, Total Val Loss=1.952101, Total Val ACC=0.579760]\n",
            "88it [05:48,  3.97s/it, Epoch=20, LR=0.0001, Loss=0.758681, Total Loss=0.696215, Total ACC=0.767787]\n",
            "7it [00:04,  1.45it/s, Epoch=20, Val Loss=5.754821, Total Val Loss=1.958558, Total Val ACC=0.580479]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18a9d77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "62b36562-1678-4091-dfeb-614c5c228890"
      },
      "source": [
        "plt.plot(loss_plot, label='train_loss')\n",
        "plt.plot(val_loss_plot, label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "18a9d77a",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05310d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "46c8ac1b-4b12-4424-bfa2-d1b1717c9fc9"
      },
      "source": [
        "plt.plot(acc_plot, label='train_acc')\n",
        "plt.plot(val_acc_plot, label='val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "05310d93",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpDuYmhXP2je"
      },
      "source": [
        "### inference "
      ],
      "id": "ZpDuYmhXP2je"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c376e57"
      },
      "source": [
        "def evaluate(tokens):\n",
        "    transformer.to(device)\n",
        "    decoder_input = torch.tensor([tar_tokenizer.txt2idx['sos_']] * tokens.size(0), dtype=torch.long).to(device)\n",
        "    output = decoder_input.unsqueeze(1).to(device)\n",
        "    enc_output = None\n",
        "    for i in range(decoder_len-1):        \n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        with torch.no_grad():\n",
        "            predictions, attention_weights, enc_output = transformer([tokens, output, enc_output])\n",
        "        \n",
        "        # select the last token from the seq_len dimension\n",
        "        predictions_ = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "        \n",
        "        predicted_id = torch.tensor(torch.argmax(predictions_, axis=-1), dtype=torch.int32)\n",
        "        \n",
        "        output = torch.cat([output, predicted_id], dim=-1)\n",
        "    output = output.cpu().numpy()\n",
        "    \n",
        "    summary_list = []\n",
        "    token_list = []\n",
        "    for token in output:\n",
        "        summary = tar_tokenizer.convert(token)\n",
        "        summary_list.append(summary)\n",
        "        token_list.append(token)\n",
        "    return summary_list, token_list"
      ],
      "id": "6c376e57",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81254fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d574d0d4-b1ce-4dc9-ee7c-feaa82ace427"
      },
      "source": [
        "tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "preds = []\n",
        "tokens = []\n",
        "for batch, batch_item in tqdm_dataset:\n",
        "    output = evaluate(batch_item['src_token'].to(device))\n",
        "    preds.extend(output[0])\n",
        "    tokens.extend(output[1])"
      ],
      "id": "81254fc4",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:42,  6.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfc8ab45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba7ca47-72b7-4f9a-b09c-f9d01baa2195"
      },
      "source": [
        "for i, (a, p) in enumerate(zip(df_val.summary, preds)):\n",
        "    print('정답 :', a)\n",
        "    print('예측 :', p)\n",
        "    print('=================================================================================')\n",
        "    if i == 10:\n",
        "        break"
      ],
      "id": "dfc8ab45",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답 : 음성군 경로당 지원 조례 일부개정조례안은 경로당 이용에 대한 여건 및 특수성에 따라 기존 미등록 경로당 등록기준을 완화하고, 경로당 양곡 지원에 대한 근거를 마련하는 등 경로당 이용 어르신들의 건강증진 및 복지향상에 기여하기 위해 개정함. 해당 안건은 가결되었음.\n",
            "예측 :  음성군 기업 및 투자 유치 촉진 조례 일부 개정 조례 안은 < 지방 자치 단체의지방 자치 단체의지방 자치 단체의지방 자치 단체의지방 자치 단체의지방 자치 단체의회의를 위한 조례에 관한 법률 > 제 4 항\n",
            "=================================================================================\n",
            "정답 : 음성군 군세 징수 조례 일부개정조례안과 2019년 재산세 도시지역분 적용대상 지역 고시안은 <음성군 행정기구 설치 조례>가 2019년 1월 1일 전부개정됨에 따라 변경된 사항을 조례에 반영하기 위해 제정함. 해당 안건은 가결되었음.\n",
            "예측 :  음성군 지방 세입 징수 포상금 지급 조례 일부 개정 조례 안은 < 지방 자치 법 > 제 4 항에 따라 음성군 지방 자치 단체의규정에 따라 음성군 의회 회의 의결 사항을 반영하고자 제정되었으며 , 해당 안건은 가결\n",
            "=================================================================================\n",
            "정답 : 음성군 폐기물 관리 조례 일부개정조례안은 쓰레기처리비 대비 수수료 수입비율인 주민부담율이 낮아 청소행정의 건전 재정을 저해하고 불법반입 폐기물이 증가하는 문제가 있어 지역 실정에 맞도록 쓰레기 종량제 수수료를 조정하고자 제정함. 해당 안건은 가결 되었음.\n",
            "예측 :  음성군 군세 감면 조례 일부 개정 조례 안은 < 지방세 기본법 > 제 4 항의규정에 의거 음성군 군세 감면 조례의규정에 의거하여 음성군 군세 감면 조례의규정에 대한 자동차세 감면 조례의규정을 반영하고 , 해\n",
            "=================================================================================\n",
            "정답 : 음성군 농업기계 사후관리 출장비용 지원 조례안은 음성군 농업인의 농업생산성 향상과 경영 개선, 기계화 영농 편의 등을 제공하고 농업기계 안전사용을 도모하기 위해 제정함. 해당 안건은 가결되었음.\n",
            "예측 :  음성군 기업 및 투자 유치 촉진 조례 안은 지역 경제 활성 화에 필요한 사항을 규정하여 지역 경제 활성 화를 도모하기 위해 제정하였으며 , 해당 안건은 가결됨. 음성군 지역 경제 활성 화에 필요한 사\n",
            "=================================================================================\n",
            "정답 : 일반농산어촌개발사업 공유재산 시설물 관리위탁 운영 동의안은 조성한 시설물의 효율적인 관리를 위해 추진위원회에 그 재산의 관리를 위탁하고자 하는 것에 동의를 구하기 위해 발의됨. 해당 안건은 가결되었음.\n",
            "예측 :  주요 사업 현지 확인 특별 위원회 구성 결의안은 3 월 30 일부터 3 월 30 일까지 5 일 간 운영함. 음성군 현안 사업의경우 회의 의결을 위해 구성 및 운영하고 , 사업 추진 상의문제점 및 운영하고\n",
            "=================================================================================\n",
            "정답 : 제251회 음성군의회 제2차 정례회 제3차 본회의 개의.\n",
            "예측 :  음성군 의회 정례회의운영에 관한 조례 안은 제 3 차 정례회의개의선포 . 금번 임시회는 음성군 의회 정례회 기간 중에 따라 음성군 의회 정례회 기간 중에 관한 조례로 조정 및 답변 사항을 위해 제정하기 위해 제\n",
            "=================================================================================\n",
            "정답 : 2014년도 세입 세출예산안이 가결됨. 2014년도 기금운용계획안이 가결됨.\n",
            "예측 :  2004 년도 세입 세출 예산안 승인의건과 2017 년도 기금 운용 계획안 승인의건은 심사 결과 가결됨.\n",
            "=================================================================================\n",
            "정답 : 2013~2017년도 음성군 중기지방재정계획 보고. 분야별 세부사업 계획 속에 현재 진행되고 있는 사업의 보고가 누락된 부분을 시정할 것.\n",
            "예측 :  2015 년도 주요 업무 보고의건은 평생 학습과 , 회계 과 , 회계 과 , 2019 년도 제 1 회 세입 세출 추가 경정 예산안과 세출 예산안과 세출 예산안과 세출 예산안 승인의건은 심사 결과 가결됨.\n",
            "=================================================================================\n",
            "정답 : 음성군 행정기구 설치 조례 일부개정조례안은 각종 시설물과 조직을 효율적으로 관리하고자 제정되었으며, 해당 안건은 가결됨. 음성군 지방공무원 정원 조례 일부개정조례안은 총액인건비 기준 정원으로 정원을 감축함으로써 신규사업 등에 따른 각종 페널티를 방지하고 기능직 등을 일반직으로 직종 개편하고자 제안함.\n",
            "예측 :  음성군 지방 공무원 정원 조례 일부 개정 조례 안은 < 지방 자치 단체의행정 기구와 정원 조례 > 제 4 조제 2 항에 따라 지방 공무원 정원 조례의규정에 관한 법률 > 제 4 항에 따라 지방 자치 단체의규정\n",
            "=================================================================================\n",
            "정답 : 음성군 건축 조례 일부개정조례안은 법령에서 조례로 위임된 사무에 대하여 제도시행에 필요한 사항을 자치 실정에 맞도록 건축조례 일부를 개정하고자 제정되었으며, 해당 안건은 가결됨.\n",
            "예측 :  음성군 군세 조례 일부 개정 조례 안은 < 지방세 기본법 > 제 3 항의규정에 의거 음성군 군세 감면 조례의규정에 관한 법률 > 제 3 항의규정에 의거 조례의규정에 의거 조례의규정을 반영하여 필\n",
            "=================================================================================\n",
            "정답 : 12월 17일부터 12월 19일까지 휴회가 가결됨. 제4차 본회의는 12월 20일 오전 10시에 개의.\n",
            "예측 :  12 월 10 일부터 12 월 18 일까지 3 일 간 휴회가 가결됨 . 제 3 차 본회의는 12 월 21 일 오전 10 시에 개의.\n",
            "=================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0541152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c29f31-ed24-42e2-afa0-49697f3b71cc"
      },
      "source": [
        "tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
        "preds = []\n",
        "tokens = []\n",
        "for batch, batch_item in tqdm_dataset:\n",
        "    output = evaluate(batch_item['src_token'].to(device))\n",
        "    preds.extend(output[0])\n",
        "    tokens.extend(output[1])\n",
        "    \n",
        "submission = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/data/dacon/trans/sample_submission.csv')\n",
        "submission['summary'] = preds\n",
        "submission.head()\n",
        "submission.to_csv('/content/gdrive/MyDrive/Colab Notebooks/data/dacon/trans/dacon_baseline.csv', index=False)"
      ],
      "id": "e0541152",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [01:47,  6.70s/it]\n"
          ]
        }
      ]
    }
  ]
}